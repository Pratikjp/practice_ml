{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"text_generation_rnn.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"rcWa-HnGwf4z","colab_type":"code","colab":{}},"cell_type":"code","source":["#importing libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense,LSTM,Dropout\n","from keras.utils import np_utils\n","from keras.callbacks import ModelCheckpoint"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XtYUPVyu_uH2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d38ab8e9-35ac-45d6-ffd2-d3722fd07f6c","executionInfo":{"status":"ok","timestamp":1539416939992,"user_tz":-330,"elapsed":2497,"user":{"displayName":"Pratik Patil","photoUrl":"","userId":"17519623449250728281"}}},"cell_type":"code","source":["text =\"\"\"Let us return for a moment to Lady Lovelace’s objection, which stated that the machine can only do what we tell it to do. \n","One could say that a man can \"inject\" an idea into the machine, and that it will respond to a certain extent and then drop into quiescence, \n","like a piano string struck by a hammer. Another simile would be an atomic pile of less than critical size: an injected idea is to correspond to a neutron \n","entering the pile from without. Each such neutron will cause a certain disturbance which eventually dies away. If, however, the size of the pile is sufficiently \n","increased, the disturbance caused by such an incoming neutron will very likely go on and on increasing until the whole pile is destroyed. Is there a corresponding \n","phenomenon for minds, and is there one for machines? There does seem to be one for the human mind. The majority of them seem to be \"sub critical,\" i.e. to\n","correspond in this analogy to piles of sub-critical size. An idea presented to such a mind will on average give rise to less than one idea in reply. A smallish \n","proportion are supercritical. An idea presented to such a mind may give rise to a whole \"theory\" consisting of secondary, tertiary and more remote ideas.\n","Animals’ minds seem to be very definitely sub-critical. Adhering to this analogy we ask, \"Can a machine be made to be super-critical? \"\"\"\n","chars = list(set(text))\n","chars_dict = {c: i for i, c in enumerate(chars)}\n","print(len(text),len(chars))\n"],"execution_count":115,"outputs":[{"output_type":"stream","text":["1349 42\n"],"name":"stdout"}]},{"metadata":{"id":"Yd_e_wG9DSxU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0d1cf79f-adff-45e2-80cc-1be46fc078b1","executionInfo":{"status":"ok","timestamp":1539416942362,"user_tz":-330,"elapsed":2169,"user":{"displayName":"Pratik Patil","photoUrl":"","userId":"17519623449250728281"}}},"cell_type":"code","source":["seq_len = 10\n","train_x= []\n","train_y = []\n","for i in range(0, len(text) - seq_len):\n","    x_str = text[i:i+seq_len]\n","    y_str = text[i+seq_len]\n","    x = [chars_dict[c] for c in x_str] \n","    y = [chars_dict[c] for c in y_str]  \n","    train_x.append(x)\n","    train_y.append(y)\n","samples = len(train_x)\n","samples"],"execution_count":116,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1339"]},"metadata":{"tags":[]},"execution_count":116}]},{"metadata":{"id":"F5EOJD8CIYKk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"dc4f9bbf-ba1d-4954-e20f-4746e93bf447","executionInfo":{"status":"ok","timestamp":1539416944192,"user_tz":-330,"elapsed":1672,"user":{"displayName":"Pratik Patil","photoUrl":"","userId":"17519623449250728281"}}},"cell_type":"code","source":["#reshape data_x in [samples,time steps, features]\n","train_x = np.reshape(train_x, (samples, seq_len, 1))\n","print(train_x.shape)\n","#one hot encoding\n","train_x = np_utils.to_categorical(train_x,num_classes = len(chars))\n","train_y = np_utils.to_categorical(train_y,num_classes = len(chars))\n","print(train_x.shape)"],"execution_count":117,"outputs":[{"output_type":"stream","text":["(1339, 10, 1)\n","(1339, 10, 42)\n"],"name":"stdout"}]},{"metadata":{"id":"-9SvWMqERt5W","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":4386},"outputId":"ec82c91a-f1ef-41a0-bded-adce7c1bef92","executionInfo":{"status":"ok","timestamp":1539418245281,"user_tz":-330,"elapsed":1300973,"user":{"displayName":"Pratik Patil","photoUrl":"","userId":"17519623449250728281"}}},"cell_type":"code","source":["\n","model = Sequential()\n","model.add(LSTM(128, input_shape=(train_x.shape[1], train_y.shape[1]), return_sequences=True))\n","model.add(LSTM(128))\n","model.add(Dense(train_y.shape[1], activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n","model.fit(train_x, train_y, batch_size = 8,epochs=128)"],"execution_count":118,"outputs":[{"output_type":"stream","text":["Epoch 1/128\n","1339/1339 [==============================] - 15s 11ms/step - loss: 3.0936\n","Epoch 2/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 2.9993\n","Epoch 3/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 2.9619\n","Epoch 4/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 2.8921\n","Epoch 5/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 2.7896\n","Epoch 6/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 2.6713\n","Epoch 7/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 2.5893\n","Epoch 8/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 2.4971\n","Epoch 9/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 2.4072\n","Epoch 10/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 2.3133\n","Epoch 11/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 2.2030\n","Epoch 12/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 2.1018\n","Epoch 13/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 1.9873\n","Epoch 14/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 1.8481\n","Epoch 15/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 1.7180\n","Epoch 16/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 1.5802\n","Epoch 17/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 1.4425\n","Epoch 18/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 1.3070\n","Epoch 19/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 1.1773\n","Epoch 20/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 1.0587\n","Epoch 21/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.9375\n","Epoch 22/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.8182\n","Epoch 23/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.6970\n","Epoch 24/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.6007\n","Epoch 25/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.5016\n","Epoch 26/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.4313\n","Epoch 27/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.3615\n","Epoch 28/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.3017\n","Epoch 29/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.2484\n","Epoch 30/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.2195\n","Epoch 31/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.1802\n","Epoch 32/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.1642\n","Epoch 33/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.1494\n","Epoch 34/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.1262\n","Epoch 35/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.1191\n","Epoch 36/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.1110\n","Epoch 37/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.1005\n","Epoch 38/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0917\n","Epoch 39/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0897\n","Epoch 40/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0900\n","Epoch 41/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0858\n","Epoch 42/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0721\n","Epoch 43/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0697\n","Epoch 44/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0723\n","Epoch 45/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0693\n","Epoch 46/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0705\n","Epoch 47/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0676\n","Epoch 48/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0613\n","Epoch 49/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0712\n","Epoch 50/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0553\n","Epoch 51/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0638\n","Epoch 52/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0614\n","Epoch 53/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0583\n","Epoch 54/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0552\n","Epoch 55/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0619\n","Epoch 56/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0579\n","Epoch 57/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0574\n","Epoch 58/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0620\n","Epoch 59/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0526\n","Epoch 60/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0569\n","Epoch 61/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0545\n","Epoch 62/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0575\n","Epoch 63/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0545\n","Epoch 64/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0515\n","Epoch 65/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0528\n","Epoch 66/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0518\n","Epoch 67/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0523\n","Epoch 68/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0518\n","Epoch 69/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0512\n","Epoch 70/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0500\n","Epoch 71/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0497\n","Epoch 72/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0489\n","Epoch 73/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0482\n","Epoch 74/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0474\n","Epoch 75/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0469\n","Epoch 76/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0473\n","Epoch 77/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0443\n","Epoch 78/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0500\n","Epoch 79/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0474\n","Epoch 80/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0481\n","Epoch 81/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0517\n","Epoch 82/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0525\n","Epoch 83/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0465\n","Epoch 84/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0445\n","Epoch 85/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0487\n","Epoch 86/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0492\n","Epoch 87/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0467\n","Epoch 88/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0473\n","Epoch 89/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0463\n","Epoch 90/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0433\n","Epoch 91/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0482\n","Epoch 92/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0455\n","Epoch 93/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0475\n","Epoch 94/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0464\n","Epoch 95/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0457\n","Epoch 96/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0456\n","Epoch 97/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0433\n","Epoch 98/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0421\n","Epoch 99/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0434\n","Epoch 100/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0426\n","Epoch 101/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0419\n","Epoch 102/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0439\n","Epoch 103/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0425\n","Epoch 104/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0436\n","Epoch 105/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0422\n","Epoch 106/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0402\n","Epoch 107/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0405\n","Epoch 108/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0397\n","Epoch 109/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0418\n","Epoch 110/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0408\n","Epoch 111/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0475\n","Epoch 112/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0436\n","Epoch 113/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0408\n","Epoch 114/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0419\n","Epoch 115/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0386\n","Epoch 116/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0419\n","Epoch 117/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0429\n","Epoch 118/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0398\n","Epoch 119/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0406\n","Epoch 120/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0412\n","Epoch 121/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0402\n","Epoch 122/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0395\n","Epoch 123/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0394\n","Epoch 124/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0377\n","Epoch 125/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0389\n","Epoch 126/128\n","1339/1339 [==============================] - 10s 7ms/step - loss: 0.0384\n","Epoch 127/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0409\n","Epoch 128/128\n","1339/1339 [==============================] - 10s 8ms/step - loss: 0.0372\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fd42f748e80>"]},"metadata":{"tags":[]},"execution_count":118}]},{"metadata":{"id":"NG-MX_Xmdo0B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d403d550-bdda-4f2f-bd2c-c2efd6adb0ee","executionInfo":{"status":"ok","timestamp":1539418247802,"user_tz":-330,"elapsed":2225,"user":{"displayName":"Pratik Patil","photoUrl":"","userId":"17519623449250728281"}}},"cell_type":"code","source":["#test dataset\n","def reshape(x_s):\n","  t_x = []\n","  x = [chars_dict[c] for c in x_s]\n","  t_x.append(x)\n","  #one hot encoding\n","  t_x = np_utils.to_categorical(t_x,num_classes = len(chars))\n","  return t_x\n","\n","test_x = []\n","x_str = text[:seq_len]\n","test_x = reshape(x_str)\n","test_x.shape"],"execution_count":119,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 10, 42)"]},"metadata":{"tags":[]},"execution_count":119}]},{"metadata":{"id":"rz9IvDY5keFl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"decfc155-8374-4f46-f693-7746617e428c","executionInfo":{"status":"ok","timestamp":1539418256365,"user_tz":-330,"elapsed":6026,"user":{"displayName":"Pratik Patil","photoUrl":"","userId":"17519623449250728281"}}},"cell_type":"code","source":["#predictions\n","res = list(x_str) \n","num_chars = 150\n","for i in range(num_chars):\n","  prediction = model.predict(test_x, verbose=0)\n","  index = np.argmax(prediction)\n","  pred_char = chars[index]\n","  res.append(pred_char)\n","  #print(x_str,'-',pred_char)\n","  l = list(x_str) \n","  l.append(pred_char)\n","  x_str = ''.join(l)\n","  x_str = x_str[1:]\n","  test_x = reshape(x_str)\n","print(\"Actual text sample-->\\n\",text[:seq_len+(num_chars)])\n","print(\"\\nGenerated text for the sample-->\\n\",\"\".join(map(str,res)))"],"execution_count":120,"outputs":[{"output_type":"stream","text":["Actual text sample-->\n"," Let us return for a moment to Lady Lovelace’s objection, which stated that the machine can only do what we tell it to do. \n","One could say that a man can \"inject\"\n","\n","Generated text for the sample-->\n"," Let us return for a moment to Lady Lovelace’s objection, which stated that the machine, and that it will respond to a neutron \n","entering the pile from without. E\n"],"name":"stdout"}]},{"metadata":{"id":"p5znD6-nUKhC","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}